{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P3: OpenStreetMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using data form the north-eastern part of Berlin, Germany. It's the place I live and spend most of my time around, so it's interesting to see what the OpenStreetMap data for it looks like.\n",
    "\n",
    "First things first, all the necessary imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import csv\n",
    "import codecs\n",
    "import re\n",
    "\n",
    "OSMFILE = 'berlin_nordost.osm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to audit street names and phone numbers, as these have a large probability of having been messed up. \n",
    "\n",
    "Having run my auditing script against a list of expected German street types and a promising initial formatting of phone number strings, this is what I got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streets:\n",
      "[   'Berliner Freiheit',\n",
      "    'Prenzlauer Berg',\n",
      "    'Hinter der Katholischen Kirche',\n",
      "    'Greifswalder Strasse',\n",
      "    'Bissingzeile',\n",
      "    u'Am Kr\\xf6gel',\n",
      "    'Spittelmarkt',\n",
      "    'Am Wriezener Bahnhof',\n",
      "    u'Potsdamer Br\\xfccke',\n",
      "    'Alice-und-Hella-Hirsch-Ring',\n",
      "    'Gabriel Marx Str',\n",
      "    'Wiener Str.',\n",
      "    'Am Schweizer Garten',\n",
      "    'Am Park',\n",
      "    'Kottbusser Damm',\n",
      "    'Zur Innung',\n",
      "    'Konrad-Adenauer-Str.',\n",
      "    'Alexandrinenstr.',\n",
      "    'Am Ostbahnhof',\n",
      "    'Unter den Linden',\n",
      "    'sredzkistrasse',\n",
      "    u'An der Schillingbr\\xfccke',\n",
      "    'James-Simon-Park',\n",
      "    'Palmkernzeile',\n",
      "    'winsstrasse',\n",
      "    'Hackescher Markt',\n",
      "    'Am Lustgarten',\n",
      "    'Zur Marktflagge',\n",
      "    'Kottbusser Tor',\n",
      "    'Bethaniendamm']\n",
      "\n",
      "Phone numbers:\n",
      "[   '+49302158070',\n",
      "    '03031004289',\n",
      "    '+4930 24 08 31 08',\n",
      "    '+493027907167',\n",
      "    '030 20089463',\n",
      "    '030 440 382 95',\n",
      "    '030/41722108',\n",
      "    '03025796751',\n",
      "    '+4930499730',\n",
      "    '+49 151 67676757',\n",
      "    '+49304948878',\n",
      "    '+49 178 5647645',\n",
      "    '030 293474231',\n",
      "    '+49309252148',\n",
      "    '+4930120762422',\n",
      "    '+493 92706611',\n",
      "    '03020453802',\n",
      "    '+4930 2613377',\n",
      "    '+4930688305700',\n",
      "    '+49 (0)30 7933647',\n",
      "    '+4930 46777991 0',\n",
      "    '+4930 914266 0',\n",
      "    '+49 172 3914281',\n",
      "    '+49 151 18386518',\n",
      "    u'+49-30 \\u2013 3465 4920',\n",
      "    '+4930 261 3614',\n",
      "    '+49-30-92376457',\n",
      "    '+49176 69396260',\n",
      "    '030 97105750',\n",
      "    '+493025399260']\n"
     ]
    }
   ],
   "source": [
    "# A list of expected German street types. Each can be capitalized if it's a separate word (e.g. Prenzlauer Allee), \n",
    "# or lowercase if it's all one word (e.g. Kastanienallee). Unicode coding for \"ß\" and \"ü\" is necessary.\n",
    "expected = [u\"Stra\\xdfe\", u\"stra\\xdfe\", \"Allee\", \"allee\", \"Weg\", \"weg\", \"Platz\", \"platz\", \"Gasse\", \"gasse\", \n",
    "            \"Promenade\", \"promenade\", \"Ufer\", \"ufer\", u\"Br\\00fccke\", u\"br\\00fccke\"]\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    ''' \n",
    "    If unexpected street type, add to set.\n",
    "    '''\n",
    "    counter = 0\n",
    "    for street_type in expected:\n",
    "        if street_type in street_name:\n",
    "            counter += 1\n",
    "    if counter == 0:\n",
    "        street_types.add(street_name)\n",
    "        \n",
    "def audit_phone_num(phone_nums, num):\n",
    "    '''\n",
    "    If badly formatted phone number, add to set.\n",
    "    '''\n",
    "    if not num.startswith(\"+49 30 \"):\n",
    "        phone_nums.add(num)\n",
    "\n",
    "def is_street_name(elem):\n",
    "    '''\n",
    "    Check if the tag describes a street name.\n",
    "    '''\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def is_phone_num(elem):\n",
    "    '''\n",
    "    Check if the tag describes a phone number associated with the object.\n",
    "    '''\n",
    "    return (elem.attrib['k'] == \"phone\")\n",
    "\n",
    "def audit(osmfile):\n",
    "    '''\n",
    "    Run through all street names and phone numbers in data, return unexpected street types and numb.\n",
    "    '''\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = set([])\n",
    "    phone_nums = set([])\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "                elif is_phone_num(tag):\n",
    "                    audit_phone_num(phone_nums, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types, phone_nums\n",
    "\n",
    "street_phone_list = audit(OSMFILE)\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "print \"Streets:\"\n",
    "pp.pprint(list(street_phone_list[0])[:30])\n",
    "print \"\\nPhone numbers:\"\n",
    "pp.pprint(list(street_phone_list[1])[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, by and large these are legitimate street names that don't have a particular type. (Some weird codings in there are unicode for the German ü, ö, ä and ß). It's not uncommon in Germany to name the streets whatever (e.g. \"Am Ostbahnhof\" = \"At the Eastern Station\").\n",
    "\n",
    "But, there are some problems that I notice:\n",
    "* some street types are abbreviated, e.g. \"Str.\" instead of \"Straße\"\n",
    "* others have \"ss\" instead of \"ß\", which is an informal \"international\" variant of German orthography\n",
    "* some names are not properly capitalized\n",
    "\n",
    "As for the phone numbers, they are just one huge mess. To be fair, the existing standard format is not very well enforced, but it's a bad excuse for having such a chaos in our data, isn't it? The standard phone number format for Berlin is: +49 30 1234567. No brackets, no hyphens, no mess. Only two spaces after the country and the city codes. That's what we're going to try and make them all look like.\n",
    "\n",
    "But first, let's correct the street names. The following little function will update the names according to a pre-specified mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([   u'Alexandrinenstra\\xdfe',\n",
      "        'Alice-und-Hella-Hirsch-Ring',\n",
      "        'Alt-Moabit',\n",
      "        'Alt-Stralau',\n",
      "        'Am Berlin Museum',\n",
      "        'Am Festungsgraben',\n",
      "        'Am Flutgraben',\n",
      "        'Am Friedrichshain',\n",
      "        'Am Gutspark',\n",
      "        'Am Karlsbad',\n",
      "        u'Am Kr\\xf6gel',\n",
      "        'Am Kupfergraben',\n",
      "        u'Am K\\xf6llnischen Park',\n",
      "        'Am Lustgarten',\n",
      "        'Am Nordbahnhof',\n",
      "        'Am Nordhafen',\n",
      "        u'Am Nu\\xdfbaum',\n",
      "        'Am Ostbahnhof',\n",
      "        'Am Pankepark',\n",
      "        'Am Park',\n",
      "        'Am Postbahnhof',\n",
      "        'Am Schwanenteich',\n",
      "        'Am Schweizer Garten',\n",
      "        u'Am Sch\\xe4fersee',\n",
      "        'Am Speicher',\n",
      "        'Am Stadtpark',\n",
      "        'Am Steinberg',\n",
      "        'Am Treptower Park',\n",
      "        'Am Viehhof',\n",
      "        'Am Wasserturm',\n",
      "        'Am Weidendamm',\n",
      "        'Am Weingarten',\n",
      "        'Am Wriezener Bahnhof',\n",
      "        'Am Zeughaus',\n",
      "        'Am Zirkus',\n",
      "        'Am Zwirngraben',\n",
      "        u'An den Eldenaer H\\xf6fen',\n",
      "        u'An den Feldtmanng\\xe4rten',\n",
      "        u'An den Knabenh\\xe4usern',\n",
      "        'An den Treptowers',\n",
      "        'An der Bucht',\n",
      "        'An der Industriebahn',\n",
      "        u'An der Kieler Br\\xfccke',\n",
      "        'An der Kolonnade',\n",
      "        u'An der Michaelbr\\xfccke',\n",
      "        'An der Ostbahn',\n",
      "        u'An der Schillingbr\\xfccke',\n",
      "        u'An der Spandauer Br\\xfccke',\n",
      "        u'Berkenbr\\xfccker Steig',\n",
      "        'Berliner Freiheit',\n",
      "        'Bethaniendamm',\n",
      "        'Bissingzeile',\n",
      "        u'B\\xf6tzowstra\\xdfe',\n",
      "        'Charlotte-Salomon-Hain',\n",
      "        'DGZ-Ring',\n",
      "        u'Danziger Stra\\xdfe',\n",
      "        u'Dar\\xdfer Bogen',\n",
      "        'Dora-Benjamin-Park',\n",
      "        'Engeldamm',\n",
      "        'Erkelenzdamm',\n",
      "        'Ernst-Reuter-Siedlung',\n",
      "        'Eschengraben',\n",
      "        'Esplanade',\n",
      "        'Fischerinsel',\n",
      "        'Fischzug',\n",
      "        'Frankfurter Tor',\n",
      "        'Friedrichsgracht',\n",
      "        u'Gabriel Marx Stra\\xdfe',\n",
      "        'Gendarmenmarkt',\n",
      "        u'Genslerstra\\xdfe',\n",
      "        u'Gerichtstra\\xdfe',\n",
      "        u'Gis\\xe8le-Freund-Hain',\n",
      "        u'Graefestra\\xdfe',\n",
      "        u'Greifswalder Stra\\xdfe',\n",
      "        'Hackescher Markt',\n",
      "        'Helenenhof',\n",
      "        u'Hinter dem Gie\\xdfhaus',\n",
      "        'Hinter dem Zeughaus',\n",
      "        'Hinter der Katholischen Kirche',\n",
      "        u'Hochstra\\xdfe',\n",
      "        u'In den Florag\\xe4rten',\n",
      "        u'In den Ministerg\\xe4rten',\n",
      "        u'Inselbr\\xfccke',\n",
      "        'Jakob-Maria-Mierscheid-Steg',\n",
      "        'James-Simon-Park',\n",
      "        u'Kissingenstra\\xdfe',\n",
      "        u'Koethener Stra\\xdfe',\n",
      "        u'Konrad-Adenauer-Stra\\xdfe',\n",
      "        'Kottbusser Damm',\n",
      "        'Kottbusser Tor',\n",
      "        u'K\\xf6llnischer Park',\n",
      "        'Legiendamm',\n",
      "        'Leuschnerdamm',\n",
      "        'Markgrafendamm',\n",
      "        'Marthashof',\n",
      "        'Mehringdamm',\n",
      "        u'Mohrenstra\\xdfe',\n",
      "        'Molkenmarkt',\n",
      "        u'Monbijoubr\\xfccke',\n",
      "        u'M\\xfchlendamm',\n",
      "        'Neue Welt',\n",
      "        u'Oranienburger Stra\\xdfe',\n",
      "        u'Oranienstra\\xdfe',\n",
      "        'Orankestrand',\n",
      "        'Palmkernzeile',\n",
      "        'Parkaue',\n",
      "        u'Potsdamer Br\\xfccke',\n",
      "        'Prenzlauer Berg',\n",
      "        'Saaler Bogen',\n",
      "        'Schiffbauerdamm',\n",
      "        'Segitzdamm',\n",
      "        u'Skalitzer Stra\\xdfe',\n",
      "        'Spittelmarkt',\n",
      "        u'Sredzkistra\\xdfe',\n",
      "        'Stadtbahnbogen',\n",
      "        u'Stresemannstra\\xdfe',\n",
      "        'Unter den Linden',\n",
      "        'Viehtrift',\n",
      "        'Vor dem Schlesischen Tor',\n",
      "        'Werderscher Markt',\n",
      "        'Werftendensteig',\n",
      "        u'Wiener Stra\\xdfe',\n",
      "        u'Winsstra\\xdfe',\n",
      "        'Wriezener Karree',\n",
      "        u'Zimmerstra\\xdfe',\n",
      "        u'Zur B\\xf6rse',\n",
      "        'Zur Innung',\n",
      "        'Zur Marktflagge',\n",
      "        'Zur Waage'])\n"
     ]
    }
   ],
   "source": [
    "mapping = { \"Str.\": u\"Stra\\xdfe\",\n",
    "            \"Strasse\": u\"Stra\\xdfe\",\n",
    "            \"Str\": u\"Stra\\xdfe\",\n",
    "            \"str\": u\"stra\\xdfe\",\n",
    "            \"str.\": u\"stra\\xdfe\",\n",
    "            \"strasse\": u\"stra\\xdfe\"\n",
    "            }\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    '''\n",
    "    If a street name is inappropriately abbreviated or not properly capitalized, fix it\n",
    "    '''\n",
    "    for key in mapping.keys():\n",
    "        if name.endswith(key):\n",
    "            name = name.replace(key, mapping[key])\n",
    "    if name[0].islower():\n",
    "        name = name.capitalize()\n",
    "    return name\n",
    "\n",
    "street_list_upd = set([])\n",
    "for street in street_list:\n",
    "    street_list_upd.add(update_name(street, mapping))\n",
    "    \n",
    "pp.pprint(street_list_upd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get to those phone numbers. This is going to be a bit trickier.\n",
    "\n",
    "I'll try my best with the following function. It should catch all landline numbers, but any mobiles will have their mobile operator code not separated by a white space. There are just too many different ones to take them all into account. Still, it's good enough for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+49 30 2158070\n",
      "+49 30 31004289\n",
      "+49 30 24083108\n",
      "+49 30 27907167\n",
      "+49 30 20089463\n",
      "+49 30 44038295\n",
      "+49 30 41722108\n",
      "+49 30 25796751\n",
      "+49 30 499730\n",
      "+49 15167676757\n",
      "+49 30 4948878\n",
      "+49 1785647645\n",
      "+49 30 293474231\n",
      "+49 30 9252148\n",
      "+49 30 120762422\n",
      "+49 392706611\n",
      "+49 30 20453802\n",
      "+49 30 2613377\n",
      "+49 30 688305700\n",
      "+49 30 7933647\n",
      "+49 30 467779910\n",
      "+49 30 9142660\n",
      "+49 1723914281\n",
      "+49 15118386518\n",
      "+49 30 34654920\n",
      "+49 30 2613614\n",
      "+49 30 92376457\n",
      "+49 17669396260\n",
      "+49 30 97105750\n",
      "+49 30 25399260\n"
     ]
    }
   ],
   "source": [
    "def update_phone_num(num):\n",
    "    '''\n",
    "    Strip phone number of all non-numeric characters, then bring it to the standard format of \"+49 30 1234567\"\n",
    "    (or as close to it as possible)\n",
    "    '''\n",
    "    num = re.sub('[^0-9]','', num)\n",
    "    if num.startswith('0049'):\n",
    "        num = '+' + num.lstrip('00')\n",
    "    if not num.startswith('49'):\n",
    "        if num.startswith('0'):\n",
    "            num = '+49 ' + num.lstrip('0')\n",
    "        else:\n",
    "            num = '+49 ' + num\n",
    "    else:\n",
    "        num = '+49 ' + num.lstrip('49')\n",
    "    if '30' in num:\n",
    "        num_spl = num.split('30', 1)\n",
    "        if len(num_spl[0]) <= 5:\n",
    "            num = num_spl[1]\n",
    "            num = '+49 30 ' + num\n",
    "            return num\n",
    "        else:\n",
    "            return num\n",
    "    else:\n",
    "        return num\n",
    "\n",
    "for num in list(street_phone_list[1])[:30]:\n",
    "    print update_phone_num(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks much better.\n",
    "\n",
    "Having tidied the data up a bit, it's now time to create csv files that will be imported into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    for tag in element.iter(\"tag\"):\n",
    "        if tag.get(\"k\") == \"addr:street\":\n",
    "            d = {\"id\": element.get(\"id\"),\n",
    "                 \"value\": update_name(tag.get(\"v\"), mapping)}\n",
    "        elif tag.get(\"k\") == \"phone\":\n",
    "            d = {\"id\": element.get(\"id\"),\n",
    "                 \"value\": update_phone_num(tag.get(\"v\"))}\n",
    "        else:\n",
    "            d = {\"id\": element.get(\"id\"),\n",
    "                 \"value\": tag.get(\"v\")}\n",
    "        check = PROBLEMCHARS.search(tag.get(\"k\"))\n",
    "        if not check:\n",
    "            m = LOWER_COLON.search(tag.get(\"k\"))\n",
    "            if m:\n",
    "                sp = tag.get(\"k\").split(\":\", 1)\n",
    "                d[\"type\"] = sp[0]\n",
    "                d[\"key\"] = sp[1]\n",
    "            else:\n",
    "                d[\"type\"] = \"regular\"\n",
    "                d[\"key\"] = tag.get(\"k\")\n",
    "        tags.append(d)\n",
    "    \n",
    "    if element.tag == 'node':\n",
    "        for attr in node_attr_fields:\n",
    "            node_attribs[attr] = element.get(attr)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        for attr in way_attr_fields:\n",
    "            way_attribs[attr] = element.get(attr)\n",
    "        pos = 0\n",
    "        for nd in element.iter(\"nd\"):\n",
    "            d = {\"id\": element.get(\"id\"),\n",
    "                 \"node_id\": nd.get(\"ref\"),\n",
    "                 \"position\": pos}\n",
    "            way_nodes.append(d)\n",
    "            pos += 1\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "process_map(OSMFILE, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives me the csv files which I then manually import into an sqlite database through the sqlite command line tool. \n",
    "\n",
    "First, I create the corresponding tables according to the schema found in p3_osm_schema.sql. Then I import the csv's with .mode csv and .import.\n",
    "\n",
    "# And now: Query time!\n",
    "\n",
    "There's a convenient way to talk to databases using the python's sqlite3 module.\n",
    "\n",
    "First stop, database size (I had to actually google this, as it proved to be not very straightforward)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database size is 83476480 bytes\n",
      "That is roughly 83.5 Mb\n"
     ]
    }
   ],
   "source": [
    "import sqlite3 as sql\n",
    "\n",
    "con = sql.connect('p3_osm_data.db')\n",
    "\n",
    "with con:\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    cur.execute('PRAGMA PAGE_SIZE')\n",
    "    page_size = cur.fetchone()\n",
    "    cur.execute('PRAGMA PAGE_COUNT')\n",
    "    page_count = cur.fetchone()\n",
    "    \n",
    "    size = int(page_size[0]) * int(page_count[0])\n",
    "    \n",
    "    print 'Database size is ' + str(size) + ' bytes'\n",
    "    print 'That is roughly ' + str(round(size / float(1000000) ,1)) + ' Mb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, matches what my OS tells me.\n",
    "\n",
    "Now, some descriptives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:  545305\n",
      "Number of ways:  83368\n",
      "Number of unique users:  1997\n",
      "\n",
      "    Top 10 amenities in the region, by number: \n",
      "restaurant 1360\n",
      "bench 1072\n",
      "cafe 825\n",
      "fast_food 594\n",
      "recycling 568\n",
      "vending_machine 455\n",
      "waste_basket 431\n",
      "telephone 420\n",
      "post_box 408\n",
      "pub 376\n"
     ]
    }
   ],
   "source": [
    "N_NODES = 'SELECT COUNT(*) FROM nodes;'\n",
    "N_WAYS = 'SELECT COUNT(*) FROM ways;'\n",
    "N_UNIQUE_USERS = '''\n",
    "                SELECT COUNT(DISTINCT(e.uid))          \n",
    "                FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e;\n",
    "                '''\n",
    "TOP_10_AMENITIES = '''\n",
    "                   SELECT value, COUNT(*) as num\n",
    "                   FROM nodes_tags\n",
    "                   WHERE key='amenity'\n",
    "                   GROUP BY value\n",
    "                   ORDER BY num DESC\n",
    "                   LIMIT 10;\n",
    "                   '''\n",
    "\n",
    "with con:\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    cur.execute(N_NODES)\n",
    "    n_nodes = cur.fetchone()\n",
    "    \n",
    "    cur.execute(N_WAYS)\n",
    "    n_ways = cur.fetchone()\n",
    "    \n",
    "    cur.execute(N_UNIQUE_USERS)\n",
    "    n_unique_users = cur.fetchone()\n",
    "    \n",
    "    cur.execute(TOP_10_AMENITIES)\n",
    "    top_10_amen = cur.fetchall()\n",
    "    \n",
    "    print 'Number of nodes: ', n_nodes[0]\n",
    "    print 'Number of ways: ', n_ways[0]\n",
    "    print 'Number of unique users: ', n_unique_users[0]\n",
    "    print '\\n    Top 10 amenities in the region, by number: '\n",
    "    for amen in top_10_amen:\n",
    "        print amen[0], str(amen[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's check which cuisines are most popular, and also which leisure activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Most popular cuisines in restaurants, cafes, and fast-foods, by number:\n",
      "italian 189\n",
      "asian 95\n",
      "german 92\n",
      "kebab 79\n",
      "burger 75\n",
      "pizza 67\n",
      "regional 64\n",
      "vietnamese 63\n",
      "indian 58\n",
      "ice_cream 48\n",
      "\n",
      "    Most popular leisure activities, by number:\n",
      "playground 178\n",
      "pitch 152\n",
      "sports_centre 54\n",
      "dance 8\n",
      "adult_gaming_centre 7\n",
      "fitness_centre 6\n",
      "hackerspace 5\n",
      "park 5\n",
      "sauna 4\n",
      "music_venue 3\n"
     ]
    }
   ],
   "source": [
    "CUISINES = '''\n",
    "          SELECT nodes_tags.value, COUNT(*) as num\n",
    "          FROM nodes_tags \n",
    "              JOIN (SELECT DISTINCT(id) \n",
    "                  FROM nodes_tags \n",
    "                  WHERE value='restaurant'\n",
    "                      OR value='fast_food'\n",
    "                      OR value='cafe') i\n",
    "              ON nodes_tags.id=i.id\n",
    "          WHERE nodes_tags.key='cuisine'\n",
    "          GROUP BY nodes_tags.value\n",
    "          ORDER BY num DESC\n",
    "          LIMIT 10;\n",
    "          ''' \n",
    "LEISURE = '''\n",
    "         SELECT nodes_tags.value, COUNT(*) as num\n",
    "         FROM nodes_tags \n",
    "             JOIN (SELECT DISTINCT(id) \n",
    "                 FROM nodes_tags) i\n",
    "             ON nodes_tags.id=i.id\n",
    "         WHERE nodes_tags.key='leisure'\n",
    "         GROUP BY nodes_tags.value\n",
    "         ORDER BY num DESC\n",
    "         LIMIT 10;\n",
    "         ''' \n",
    "\n",
    "with con:\n",
    "    cur = con.cursor()\n",
    "   \n",
    "    cur.execute(CUISINES)\n",
    "    cuisines = cur.fetchall()\n",
    "    \n",
    "    cur.execute(LEISURE)\n",
    "    leisure = cur.fetchall()\n",
    "    \n",
    "    print \"    Most popular cuisines in restaurants, cafes, and fast-foods, by number:\"\n",
    "    for thing in cuisines:\n",
    "        print thing[0], str(thing[1])\n",
    "    print \"\\n    Most popular leisure activities, by number:\"\n",
    "    for thing in leisure:\n",
    "        print thing[0], str(thing[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from all the playgrounds (and 5 hackerspaces!), there are 152 \"pitches\". OpenStreetMap wiki says that pitches are all sorts of public places where sports are played. So let's see which sports you can play in the streets of north-eastern Berlin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Most popular sports in public places:\n",
      "table_tennis 132\n",
      "basketball 14\n",
      "soccer 2\n",
      "fitness 1\n",
      "multi 1\n",
      "skateboard 1\n"
     ]
    }
   ],
   "source": [
    "SPORTS = '''\n",
    "          SELECT nodes_tags.value, COUNT(*) as num\n",
    "          FROM nodes_tags \n",
    "              JOIN (SELECT DISTINCT(id) \n",
    "                  FROM nodes_tags \n",
    "                  WHERE value='pitch') i\n",
    "              ON nodes_tags.id=i.id\n",
    "          WHERE nodes_tags.key='sport'\n",
    "          GROUP BY nodes_tags.value\n",
    "          ORDER BY num DESC\n",
    "          LIMIT 10;\n",
    "          ''' \n",
    "with con:\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    cur.execute(SPORTS)\n",
    "    sports = cur.fetchall()\n",
    "\n",
    "    print \"    Most popular sports in public places:\"\n",
    "    for thing in sports:\n",
    "        print thing[0], str(thing[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No surprise there. Table tennis is the national sport in Germany. That's right, not soccer. The number of basketball courts is somewhat surprising though.\n",
    "\n",
    "# Further exploration\n",
    "\n",
    "Now, one thing I noticed about these data is that street names appear to be not only in the tags with the \"street\" key, but also in other, non-address tags with the \"name\" key. According to the OpenStreetMap wiki, this key should describe the \"name of a place\". Putting the street name there seems non-obvious to me. So I wanted to see if my suspicion was correct and somebody systematically mis-tagged street names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Streets in 'street':\n",
      "Ackerstraße\n",
      "Adalbertstraße\n",
      "Admiralstraße\n",
      "Agnes-Wabnitz-Straße\n",
      "Albertinenstraße\n",
      "Albrechtstraße\n",
      "Alex-Wedding-Straße\n",
      "Alexanderplatz\n",
      "Alexanderstraße\n",
      "Alexanderufer\n",
      "\n",
      "    Street name duplicates:\n",
      "street name Ackerstraße\n",
      "street name Adalbertstraße\n",
      "street name Admiralstraße\n",
      "street name Agnes-Wabnitz-Straße\n",
      "street name Albertinenstraße\n",
      "street name Albrechtstraße\n",
      "street name Alex-Wedding-Straße\n",
      "street name Alexanderstraße\n",
      "street name Alexanderufer\n",
      "street name Alexandrinenstraße\n",
      "\n",
      "    Street names only in 'name' key, but not in the actual 'street' key?\n",
      "(ehemalige Hollmannstraße)\n",
      "1. Hinterhof Manteuffelstraße 103\n",
      "9. Integrierte Sekundarschule Graefestraße\n",
      "Abwasserpumpwerk Chausseestraße\n",
      "Adalberstraße\n",
      "Adalbertstraße/Oranienstraße\n",
      "Adolfstraße\n",
      "Aegirstraße\n",
      "Aidastraße\n",
      "Allgemeiner Spielplatz Gounodstraße 37-39\n",
      "\n",
      "    How many of these are there?\n",
      "503\n"
     ]
    }
   ],
   "source": [
    "STREET_STR = '''\n",
    "            SELECT value\n",
    "            FROM ways_tags\n",
    "            WHERE key = 'street'\n",
    "            GROUP BY value\n",
    "            ORDER BY value\n",
    "            LIMIT 10;\n",
    "            '''\n",
    "\n",
    "NAMES_DUPL = '''\n",
    "        SELECT a.key, b.key, a.value\n",
    "        FROM ways_tags as a, ways_tags as b\n",
    "        WHERE a.value = b.value\n",
    "            AND a.key = 'street'\n",
    "            AND b.key = 'name'\n",
    "        GROUP BY a.value\n",
    "        ORDER BY a.value\n",
    "        LIMIT 10;\n",
    "        '''\n",
    "\n",
    "STR_IN_NAMES_ONLY = '''\n",
    "                    SELECT value\n",
    "                    FROM ways_tags\n",
    "                    WHERE key = 'name'\n",
    "                        AND instr(value, 'str') > 0\n",
    "                        AND value NOT IN (SELECT value FROM ways_tags WHERE key='street')\n",
    "                    GROUP BY value\n",
    "                    ORDER BY value\n",
    "                    LIMIT 10;\n",
    "                    '''\n",
    "\n",
    "STR_IN_NAMES_ONLY_COUNT = '''\n",
    "                        SELECT COUNT(DISTINCT value)\n",
    "                        FROM ways_tags\n",
    "                        WHERE key = 'name'\n",
    "                            AND instr(value, 'str') > 0\n",
    "                            AND value NOT IN (SELECT value FROM ways_tags WHERE key='street');\n",
    "                        '''\n",
    "\n",
    "with con:\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    cur.execute(STREET_STR)\n",
    "    street_str = cur.fetchall()\n",
    "    \n",
    "    cur.execute(NAMES_DUPL)\n",
    "    names_dupl = cur.fetchall()\n",
    "    \n",
    "    cur.execute(STR_IN_NAMES_ONLY)\n",
    "    str_in_names_only = cur.fetchall()\n",
    "    \n",
    "    cur.execute(STR_IN_NAMES_ONLY_COUNT)\n",
    "    str_in_names_only_count = cur.fetchone()\n",
    "    \n",
    "    print \"\\n    Streets in 'street':\"\n",
    "    for thing in street_str:\n",
    "        print thing[0]\n",
    "    print \"\\n    Street name duplicates:\"\n",
    "    for thing in names_dupl:\n",
    "        print thing[0], thing[1], thing[2]\n",
    "    print \"\\n    Street names only in 'name' key, but not in the actual 'street' key?\"\n",
    "    for thing in str_in_names_only:\n",
    "        print thing[0]\n",
    "    print \"\\n    How many of these are there?\"\n",
    "    print str_in_names_only_count[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concluding remarks and other suggestions\n",
    "\n",
    "So my suspicions appear to have been correct. There are both duplicate streets with \"street\" and \"name\" keys, and some street names that only appear with \"name\" keys. I'm not sure what's going on here, but it seems like these latter streets could use some re-tagging. \n",
    "\n",
    "Such task would be somewhat complex however. I can imagine devising a look-up list of street names which will then be used to filter street names from everything else under the \"name\" key. But, it would not be a matter of just finding strings containing some characteristic sub-strings (like the expected street types I used in my audit), because of all the other weirdly named streets (e.g. \"Zur Waage\" - \"To the Scale\"). One could start by cleaning up all the duplicates though.\n",
    "\n",
    "On the other hand, there appear to be a lot of street names not tagged \"street\". Maybe there's something else going on? One idea is that they are still mis-tagged, and it may be a couple of users (or even one, maybe a bot), who's consistently mis-tagging street names. Another idea is that it somehow makes sense this way, and we'd have to look at all the other data for these particular objects (e.g. their location) to understand what's going on.\n",
    "\n",
    "### What else could be done to improve the dataset?\n",
    "\n",
    "Basically, improving a dataset such as this one can be seen as twofold: \n",
    "\n",
    "1) Get more data, and \n",
    "\n",
    "2) Get better data.\n",
    "\n",
    "To get more data, one idea would be to use the existing database of Pokestops from the popular game Pokemon Go. These Pokestops represent different objects in the public space, which would be a nice addition to OpenStreetMap. However, although such addition would definitely enrich our dataset, proper input can prove tricky, as the objects are sometimes wildly different (e.g. a fountain, a piece of street art, a historical monument etc.). Merging such data may have to be done manually, or programmatically but human-curated, in order for it to be labeled correctly.\n",
    "\n",
    "To get better data, mappers could for instance try to employ drones. The OpenStreetMap wiki says that aerial imaging is one of the few practical sources of accurate mapping information for buildings - so getting more aerial images using drones could prove useful, especially in areas where high-resolution images from other sources are not available. Benefits of this approach are: \n",
    "* it is in the spirit of maker/open source/DIY community\n",
    "* it may be the most precise option for mapping buildings and other objects in some areas\n",
    "* it's fun!\n",
    "\n",
    "On the other hand,\n",
    "* extra equipment is involved\n",
    "* flying drones may be illegal/difficult/dangerous in some areas\n",
    "\n",
    "Either way, there's more that could be done to improve the OpenStreetMap data, and this project has been but a small step in that direction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
